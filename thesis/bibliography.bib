@article{abbasUnmaskingDeepfakesSystematic2024,
  title = {Unmasking Deepfakes: {{A}} Systematic Review of Deepfake Detection and Generation Techniques Using Artificial Intelligence},
  shorttitle = {Unmasking Deepfakes},
  author = {Abbas, Fakhar and Taeihagh, Araz},
  date = {2024-10-15},
  journaltitle = {Expert Systems with Applications},
  shortjournal = {Expert Systems with Applications},
  volume = {252},
  pages = {124260},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2024.124260},
  url = {https://www.sciencedirect.com/science/article/pii/S0957417424011266},
  urldate = {2025-04-29},
  abstract = {Due to the fast spread of data through digital media, individuals and societies must assess the reliability of information. Deepfakes are not a novel idea but they are now a widespread phenomenon. The impact of deepfakes and disinformation can range from infuriating individuals to affecting and misleading entire societies and even nations. There are several ways to detect and generate deepfakes online. By conducting a systematic literature analysis, in this study we explore automatic key detection and generation methods, frameworks, algorithms, and tools for identifying deepfakes (audio, images, and videos), and how these approaches can be employed within different situations to counter the spread of deepfakes and the generation of disinformation. Moreover, we explore state-of-the-art frameworks related to deepfakes to understand how emerging machine learning and deep learning approaches affect online disinformation. We also highlight practical challenges and trends in implementing policies to counter deepfakes. Finally, we provide policy recommendations based on analyzing how emerging artificial intelligence (AI) techniques can be employed to detect and generate deepfakes online. This study benefits the community and readers by providing a better understanding of recent developments in deepfake detection and generation frameworks. The study also sheds a light on the potential of AI in relation to deepfakes.},
  keywords = {Artificial Intelligence (AI),Deep learning,Deepfakes,Detection and generation,Literature review,Policy recommendations}
}

@online{AIAssistedFakePorn2017,
  title = {{{AI-Assisted Fake Porn Is Here}} and {{We}}’re {{All Fucked}}},
  date = {2017-12-11T19:18:47+00:00},
  url = {https://www.vice.com/en/article/gal-gadot-fake-ai-porn/},
  urldate = {2025-05-04},
  abstract = {Someone used an algorithm to paste the face of 'Wonder Woman' star Gal Gadot onto a porn video, and the implications are terrifying.},
  langid = {american},
  organization = {VICE}
}

@online{AIRisksThat,
  title = {{{AI Risks}} That {{Could Lead}} to {{Catastrophe}} | {{CAIS}}},
  url = {https://safe.ai/ai-risk},
  urldate = {2025-07-21},
  abstract = {There are many potential risks from AI. CAIS focusses on mitigating risks that could lead to catastrophic outcomes for society, such as bioterrorism or loss of control over military AI systems.},
  langid = {english},
  organization = {Center for AI Safety}
}

@article{ajderDeeptraceLabReport,
  title = {{{DeeptraceLab Report}}},
  author = {Ajder, Henry and Patrini, Giorgio and Cavalli, Francesco and Cullen, Laurence},
  url = {https://regmedia.co.uk/2019/10/08/deepfake_report.pdf},
  langid = {english}
}

@inproceedings{aliExploringGenerativeModels2021,
  title = {Exploring {{Generative Models}} with {{Middle School Students}}},
  booktitle = {Proceedings of the 2021 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Ali, Safinah and DiPaola, Daniella and Lee, Irene and Hong, Jenna and Breazeal, Cynthia},
  date = {2021-05-07},
  series = {{{CHI}} '21},
  pages = {1--13},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3411764.3445226},
  url = {https://dl.acm.org/doi/10.1145/3411764.3445226},
  urldate = {2025-07-21},
  abstract = {Applications of generative models such as Generative Adversarial Networks (GANs) have made their way to social media platforms that children frequently interact with. While GANs are associated with ethical implications pertaining to children, such as the generation of Deepfakes, there are negligible efforts to educate middle school children about generative AI. In this work, we present a generative models learning trajectory (LT), educational materials, and interactive activities for young learners with a focus on GANs, creation and application of machine-generated media, and its ethical implications. The activities were deployed in four online workshops with 72 students (grades 5-9). We found that these materials enabled children to gain an understanding of what generative models are, their technical components and potential applications, and benefits and harms, while reflecting on their ethical implications. Learning from our findings, we propose an improved learning trajectory for complex socio-technical systems.},
  isbn = {978-1-4503-8096-6}
}

@inproceedings{altInteractionTechniquesCreating2013,
  title = {Interaction Techniques for Creating and Exchanging Content with Public Displays},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Alt, Florian and Shirazi, Alireza Sahami and Kubitza, Thomas and Schmidt, Albrecht},
  date = {2013-04-27},
  pages = {1709--1718},
  publisher = {ACM},
  location = {Paris France},
  doi = {10.1145/2470654.2466226},
  url = {https://dl.acm.org/doi/10.1145/2470654.2466226},
  urldate = {2025-04-29},
  abstract = {Falling hardware prices and ever more displays being connected to the Internet will lead to large public display networks, potentially forming a novel communication medium. We envision that such networks are not restricted to display owners and advertisers anymore, but allow also passersby (e.g., customers) to exchange content, similar to traditional public notice areas, such as bulletin boards. In this context it is crucial to understand emerging practices and provide easy and straight forward interaction techniques to be used for creating and exchanging content. In this paper, we present Digifieds, a digital public notice area we built to investigate and compare possible interaction techniques. Based on a lab study we show that using direct touch at the display as well as using the mobile phone as a complementing interaction technology are most suitable. Direct touch at the display closely resembles the interaction known from classic bulletin boards and provides the highest usability. Mobile phones preserve the users’ privacy as they exchange (sensitive) data with the display and at the same time allow content to be created on-thego or to be retrieved.},
  eventtitle = {{{CHI}} '13: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-1899-0},
  langid = {english}
}

@online{Architecture,
  title = {Architecture},
  url = {https://bloclibrary.dev/de/architecture/},
  urldate = {2025-07-16},
  abstract = {Overview of the recommended architecture patterns when using bloc.},
  langid = {ngerman},
  organization = {Bloc}
}

@article{battistaPoliticalCommunicationAge2024,
  title = {Political Communication in the Age of Artificial Intelligence: An Overview of Deepfakes and Their Implications},
  shorttitle = {Political Communication in the Age of Artificial Intelligence},
  author = {Battista, Daniele},
  date = {2024-06-30},
  journaltitle = {Society Register},
  volume = {8},
  number = {2},
  pages = {7--24},
  issn = {2544-5502},
  doi = {10.14746/sr.2024.8.2.01},
  url = {https://pressto.amu.edu.pl/index.php/sr/article/view/42182},
  urldate = {2025-06-01},
  abstract = {The current technological landscape has been profoundly shaped by rapid and significant advances in artificial intelligence (AI), sparking extraordinary interest in academia and beyond. Considered an unprecedented revolutionary technology, it has captured the attention of researchers, scholars, and professionals from various disciplines as it offers transformative prospects in a wide range of fields. This technological progress has sparked a broad debate on its social, ethical, and economic impacts, raising important questions that require in-depth and multidisciplinary investigations. AI thus emerges as an ever-evolving discipline with significant implications for the future of human progress. Besides being seen as an opportunity to pursue common societal goals, many observers have recognized the potential risks associated with such developments. Its integration into the political context also presents a promising opportunity to enhance the efficiency of political decisions however, its adoption raises significant challenges that require careful evaluation. The aim of this research is to explore in detail the relationship between AI and political communication, focusing on the analysis of AI's usage in this context while highlighting the phenomenon of deepfakes, which jeopardize democratic stability and security in many cases. The importance of this research contribution lies in the context where AI is assuming an increasingly prominent role in daily dynamics, making it essential to fully understand the implications and potential consequences of AI application in the political field. Furthermore, it is crucial to assess whether such initiatives can genuinely be considered democratic or if they could represent a dangerous trend towards the use of manipulative algorithms.},
  issue = {2},
  langid = {english},
  keywords = {Artificial Intelligence,deep fakes,democratic participation,ethical impact,political innovation}
}

@article{benaissaOverviewGANDeepFakesDetection2024,
  title = {An Overview of {{GAN-DeepFakes}} Detection: Proposal, Improvement, and Evaluation},
  shorttitle = {An Overview of {{GAN-DeepFakes}} Detection},
  author = {Ben Aissa, Fatma and Hamdi, Monia and Zaied, Mourad and Mejdoub, Mahmoud},
  date = {2024-03-01},
  journaltitle = {Multimedia Tools and Applications},
  shortjournal = {Multimed Tools Appl},
  volume = {83},
  number = {11},
  pages = {32343--32365},
  publisher = {Springer US},
  issn = {1573-7721},
  doi = {10.1007/s11042-023-16761-4},
  url = {https://link-springer-com.emedien.ub.uni-muenchen.de/article/10.1007/s11042-023-16761-4},
  urldate = {2025-06-01},
  abstract = {Image source forensics is commonly regarded as one of the most effective methods for blindly verifying the authenticity and integrity of digital images. The most recent topic related to image source forensics is the detection of DeepFakes generated using Generative adversarial networks (GANs). In recent years, with the rapid growth of GANs, a photo-realistic image can be easily generated from a random vector. Moreover, the images generated by advanced GANs are very realistic. It is reasonable to acknowledge that even a well-trained viewer has difficulties distinguishing artificial from real images. Therefore, detecting DeepFakes generated by GANs is an important task. By reviewing the background of DeepFakes detection methods, this paper aims to provide readers with a systematic understanding of GAN, its variants used to create DeepFakes, and, more crucially, methods proposed to identify DeepFakes in the literature to date.},
  issue = {11},
  langid = {english}
}

@online{bildungDeepfakesWennMan2023,
  title = {Deepfakes – Wenn man Augen und Ohren nicht mehr trauen kann},
  author = {family=Bildung, given=Bundeszentrale, prefix=für politische, useprefix=false},
  date = {2023-11-22},
  url = {https://www.bpb.de/lernen/digitale-bildung/werkstatt/542670/deepfakes-wenn-man-augen-und-ohren-nicht-mehr-trauen-kann/},
  urldate = {2025-05-02},
  abstract = {KI-Technologien bergen Risiken für Demokratie und Gesellschaft: Durch sogenannte Deepfakes wird es immer einfacher, Bilder, Videos und Audioaufnahmen zu manipulieren.},
  langid = {ngerman},
  organization = {bpb.de}
}

@online{BlocStateManagement,
  title = {Bloc State Management Library},
  url = {https://bloclibrary.dev/de/},
  urldate = {2025-07-16},
  abstract = {Official documentation for the bloc state management library. Support for Dart, Flutter, and AngularDart. Includes examples and tutorials.},
  langid = {ngerman},
  organization = {Bloc}
}

@article{chawlaDeepfakesHowPervert2019,
  title = {Deepfakes : {{How}} a Pervert Shook the World},
  shorttitle = {Deepfakes},
  author = {Chawla, R.},
  date = {2019-06-22},
  journaltitle = {International Journal for Advance Research and Development},
  url = {https://www.semanticscholar.org/paper/Deepfakes-:-How-a-pervert-shook-the-world-Chawla/c3b3a6d27dbbfed4df630b39fc0a8a6692b1828a},
  urldate = {2025-05-29},
  abstract = {Recently a software has made it easy to create hyper-realistic face swaps in videos that leaves little-to-no traces of manipulation, in what is known as “deepfake” videos. Scenarios, where these AI manipulated/generated videos, are used for political distress, blackmail or even terrorism are easily envisioned as a near dystopia. This paper explores the various aspects of deepfake videos including its consequences and newly developed innovations in detecting deepfakes.}
}

@article{chesneyDeepfakesNewDisinformation2019,
  title = {Deepfakes and the {{New Disinformation War}}: {{The Coming Age}} of {{Post-Truth Geopolitics}}.},
  shorttitle = {Deepfakes and the {{New Disinformation War}}},
  author = {Chesney, Robert and Citron, Danielle},
  date = {2019-01-01},
  journaltitle = {Foreign Affairs},
  volume = {98},
  number = {1},
  pages = {147--156},
  publisher = {Council on Foreign Relations, Inc.},
  issn = {00157120},
  url = {https://go-gale-com.emedien.ub.uni-muenchen.de/ps/i.do?p=AONE&sw=w&issn=00157120&v=2.1&it=r&id=GALE%7CA566263296&sid=googleScholar&linkaccess=abs},
  urldate = {2025-04-30},
  abstract = {{$<$}em{$>$}Gale{$<$}/em{$>$} Academic OneFile includes Deepfakes and the New Disinformation War: The Coming Ag by Robert Chesney and Danielle Citron. Click to explore.},
  langid = {english}
}

@article{ciftciFakeCatcherDetectionSynthetic2020,
  title = {{{FakeCatcher}}: {{Detection}} of {{Synthetic Portrait Videos}} Using {{Biological Signals}}},
  shorttitle = {{{FakeCatcher}}},
  author = {Ciftci, Umur Aybars and Demir, Ilke and Yin, Lijun},
  date = {2020},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  pages = {1--1},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2020.3009287},
  url = {https://ieeexplore.ieee.org/document/9141516},
  urldate = {2025-04-30},
  abstract = {The recent proliferation of fake portrait videos poses direct threats on society, law, and privacy [1]. Believing the fake video of a politician, distributing fake pornographic content of celebrities, fabricating impersonated fake videos as evidence in courts are just a few real world consequences of deep fakes. We present a novel approach to detect synthetic content in portrait videos, as a preventive solution for the emerging threat of deep fakes. In other words, we introduce a deep fake detector. We observe that detectors blindly utilizing deep learning are not effective in catching fake content, as generative models produce formidably realistic results. Our key assertion follows that biological signals hidden in portrait videos can be used as an implicit descriptor of authenticity, because they are neither spatially nor temporally preserved in fake content. To prove and exploit this assertion, we first engage several signal transformations for the pairwise separation problem, achieving 99.39\% accuracy. Second, we utilize those findings to formulate a generalized classifier for fake content, by analyzing proposed signal transformations and corresponding feature sets. Third, we generate novel signal maps and employ a CNN to improve our traditional classifier for detecting synthetic content. Lastly, we release an "in the wild" dataset of fake portrait videos that we collected as a part of our evaluation process. We evaluate FakeCatcher on several datasets, resulting with 96\%, 94.65\%, 91.50\%, and 91.07\% accuracies, on Face Forensics [2], Face Forensics++ [3], CelebDF [4], and on our new Deep Fakes Dataset respectively. In addition, our approach produces a significantly superior detection rate against baselines, and does not depend on the source, generator, or properties of the fake content. We also analyze signals from various facial regions, under image distortions, with varying segment durations, from different generators, against unseen datasets, and under several dimensionality reduction techniques.},
  keywords = {authenticity classification,biological signals,Biological system modeling,deep fakes,Detectors,Face,fake detection,Feature extraction,Gallium nitride,generative models,image forensics,Videos}
}

@article{coenraadExperiencingCybersecurityOne2020,
  title = {Experiencing {{Cybersecurity One Game}} at a {{Time}}: {{A Systematic Review}} of {{Cybersecurity Digital Games}}},
  shorttitle = {Experiencing {{Cybersecurity One Game}} at a {{Time}}},
  author = {Coenraad, Merijke and Pellicone, Anthony and Ketelhut, Diane Jass and Cukier, Michel and Plane, Jan and Weintrop, David},
  date = {2020-10-01},
  journaltitle = {Simulation \& Gaming},
  volume = {51},
  number = {5},
  pages = {586--611},
  publisher = {SAGE Publications Inc},
  issn = {1046-8781},
  doi = {10.1177/1046878120933312},
  url = {https://doi.org/10.1177/1046878120933312},
  urldate = {2025-04-29},
  abstract = {Background. Cybersecurity is of increasing importance in our interconnected world, yet the field has a growing workforce deficit and an underrepresentation of women and people of color. In an effort to address these issues, many digital games have been created to teach individuals about cybersecurity and keeping themselves, their data, and their networks safe.Intervention. We present the results of a systematic review of digital games related to cybersecurity as a means to understand how players are being introduced to cybersecurity in game-based contexts.Methods. Using a systematic search, we identified 181 games related to cybersecurity (either through content or aesthetics) by searching the Apple App Store, the Google Play Store, Steam, and the web broadly. Each game was played for up to an hour and characteristics such as the game story, game elements, and presentation of cybersecurity were gathered.Results. We found diverse conceptualizations of cybersecurity and of cybersecurity professionals. Further, the nature of games and the framing of cybersecurity varied by the platform and device on which the game was available (computer, mobile, or web). Web games were most likely to present cybersecurity as cyber safety and were more likely to be a gamified quiz or worksheet. Computer and mobile games tended to present cybersecurity through game aesthetics or deep content engagement. The games mirrored the underrepresentation of women and minoritized individuals in the field.Discussion. With the variety of digital cybersecurity games and the differences in games based on the platform on which the game is available, it is important game developers move beyond presenting cybersecurity through gamification and focusing on cyber safety. The current scope of cybersecurity games leaves room for the development of games focused on deeper content engagement with cybersecurity topics in an environment conducive to the broadening participation goals of the cybersecurity field.},
  langid = {english}
}

@article{cybenkoAIFakeNews2018,
  title = {{{AI}} and {{Fake News}}},
  author = {Cybenko, Anne K. and Cybenko, George},
  date = {2018-09-01},
  journaltitle = {IEEE Intelligent Systems},
  volume = {33},
  number = {5},
  pages = {1--5},
  issn = {1541-1672},
  doi = {10.1109/MIS.2018.2877280},
  url = {https://doi.org/10.1109/MIS.2018.2877280},
  urldate = {2025-05-29},
  abstract = {Fake news and propaganda are not new phenomena but when powered by modern information dissemination and AI technologies, they are manifesting themselves at scales and in ways previously not possible. This paper describes several human frailties that make today's “fake news” possible together with several AI-based technologies that can help defeat or defend those frailties. Our goal is to explore ways in which AI can play a role in the “fake news” arena.}
}

@online{CyberSecurityAwareness,
  title = {Cyber {{Security Awareness Month Digital Resources}}},
  url = {https://its.utoronto.ca/cyberaware_digital/},
  urldate = {2025-07-16},
  abstract = {View and download available posters for display in your office or classroom.},
  langid = {american},
  organization = {Information Technology Services - University of Toronto}
}

@article{daviesOpenDisplayNetworks2012,
  title = {Open {{Display Networks}}: {{A Communications Medium}} for the 21st {{Century}}},
  shorttitle = {Open {{Display Networks}}},
  author = {Davies, Nigel and Langheinrich, Marc and Jose, Rui and Schmidt, Albrecht},
  date = {2012-05},
  journaltitle = {Computer},
  volume = {45},
  number = {5},
  pages = {58--64},
  publisher = {{Institute of Electrical and Electronics Engineers (IEEE)}},
  issn = {0018-9162},
  doi = {10.1109/mc.2012.114},
  url = {http://ieeexplore.ieee.org/document/6174992/},
  urldate = {2025-07-16}
}

@online{DeepfakeDetectionChallenge,
  title = {Deepfake {{Detection Challenge Results}}: {{An}} Open Initiative to Advance {{AI}}},
  url = {https://ai.meta.com/blog/deepfake-detection-challenge-results-an-open-initiative-to-advance-ai/},
  urldate = {2025-07-22}
}

@online{DeepfakeDetectionChallengea,
  title = {Deepfake {{Detection Challenge}}},
  url = {https://kaggle.com/deepfake-detection-challenge},
  urldate = {2025-07-22},
  abstract = {Identify videos with facial or voice manipulations},
  langid = {english}
}

@online{DeepfakesGefahrenUnd,
  title = {Deepfakes - Gefahren und Gegenmaßnahmen},
  url = {https://www.bsi.bund.de/DE/Themen/Unternehmen-und-Organisationen/Informationen-und-Empfehlungen/Kuenstliche-Intelligenz/Deepfakes/deepfakes.html?nn=1009560},
  urldate = {2025-04-30},
  langid = {ngerman},
  organization = {Bundesamt für Sicherheit in der Informationstechnik}
}

@article{dielHumanPerformanceDetecting2024,
  title = {Human Performance in Detecting Deepfakes: {{A}} Systematic Review and Meta-Analysis of 56 Papers},
  shorttitle = {Human Performance in Detecting Deepfakes},
  author = {Diel, Alexander and Lalgi, Tania and Schröter, Isabel Carolin and MacDorman, Karl F. and Teufel, Martin and Bäuerle, Alexander},
  date = {2024-12-01},
  journaltitle = {Computers in Human Behavior Reports},
  shortjournal = {Computers in Human Behavior Reports},
  volume = {16},
  pages = {100538},
  issn = {2451-9588},
  doi = {10.1016/j.chbr.2024.100538},
  url = {https://www.sciencedirect.com/science/article/pii/S2451958824001714},
  urldate = {2025-07-11},
  abstract = {Deepfakes are AI-generated media designed to look real, often with the intent to deceive. Deepfakes threaten public and personal safety by facilitating disinformation, propaganda, and identity theft. Though research has been conducted on human performance in deepfake detection, the results have not yet been synthesized. This systematic review and meta-analysis investigates human deepfake detection accuracy. Searches in PubMed, ScienceGov, JSTOR, Google Scholar, and paper references, conducted in June and October 2024, identified empirical studies measuring human detection of high-quality deepfakes. After pooling accuracy, odds-ratio, and sensitivity (d') effect sizes (k~=~137 effects) from 56 papers involving 86,155 participants, we analyzed 1) overall deepfake detection performance, 2) performance across stimulus types (audio, image, text, and video), and 3) the effects of detection-improvement strategies. Overall deepfake detection rates (sensitivity) were not significantly above chance because 95\% confidence intervals crossed 50\%. Total deepfake detection accuracy was 55.54\% (95\% CI [48.87, 62.10], k~=~67). For audio, accuracy was 62.08\% [38.23, 83.18], k~=~8; for images, 53.16\% [42.12, 64.64], k~=~18; for text, 52.00\% [37.42, 65.88], k~=~15; and for video, 57.31\% [47.80, 66.57], k~=~26. Odds ratios were 0.64 [0.52, 0.79], k~=~62, indicating 39\% detection accuracy, below chance (audio 45\%, image 35\%, text 40\%, video 40\%). Moreover, d' values show no significant difference from chance. However, strategies like feedback training, AI support, and deepfake caricaturization improved detection performance above chance levels (65.14\% [55.21, 74.46], k~=~15), especially for video stimuli.},
  keywords = {Accuracy,AI-generated content,Deepfake,Human detection,Synthetic face}
}

@online{engagementGuidesDetermineCredibility,
  title = {Guides: {{Determine Credibility}} ({{Evaluating}}): {{Deepfakes}}},
  shorttitle = {Guides},
  author = {Engagement, Instruction {and} Student},
  url = {https://guides.library.illinoisstate.edu/evaluating/deepfakes},
  urldate = {2025-07-16},
  abstract = {Using credible and relevant sources is important. Learn what questions to ask and some strategies to apply for determining if your source is or isn't appropriate for your project.},
  langid = {english}
}

@online{ExperiencingCybersecurityOne,
  title = {Experiencing {{Cybersecurity One Game}} at a {{Time}}: {{A Systematic Review}} of {{Cybersecurity Digital Games}}},
  shorttitle = {Experiencing {{Cybersecurity One Game}} at a {{Time}}},
  doi = {10.1177/1046878120933312},
  url = {https://journals.sagepub.com/doi/epub/10.1177/1046878120933312},
  urldate = {2025-05-12},
  langid = {english}
}

@inproceedings{gamagePDFEmergenceDeepfakes,
  title = {({{PDF}}) {{The Emergence}} of {{Deepfakes}} and Its {{Societal Implications}}: {{A Systematic Review}}},
  shorttitle = {({{PDF}}) {{The Emergence}} of {{Deepfakes}} and Its {{Societal Implications}}},
  booktitle = {{{ResearchGate}}},
  author = {Gamage, Dilrukshi and Chen, Jiayu and Sasahara, Kazutoshi},
  url = {https://www.researchgate.net/publication/355583941_The_Emergence_of_Deepfakes_and_its_Societal_Implications_A_Systematic_Review},
  urldate = {2025-07-15},
  abstract = {PDF | The appearance of Deepfake tools and technologies in the public is proliferating. Scholarly research is very centered on technology of deepfake... | Find, read and cite all the research you need on ResearchGate},
  langid = {english}
}

@article{gambinDeepfakesCurrentFuture2024,
  title = {Deepfakes: Current and Future Trends},
  shorttitle = {Deepfakes},
  author = {Gambín, Ángel Fernández and Yazidi, Anis and Vasilakos, Athanasios and Haugerud, Hårek and Djenouri, Youcef},
  date = {2024-02-19},
  journaltitle = {Artificial Intelligence Review},
  shortjournal = {Artif Intell Rev},
  volume = {57},
  number = {3},
  pages = {64},
  issn = {1573-7462},
  doi = {10.1007/s10462-023-10679-x},
  url = {https://doi.org/10.1007/s10462-023-10679-x},
  urldate = {2025-04-29},
  abstract = {Advances in Deep Learning (DL), Big Data and image processing have facilitated online disinformation spreading through Deepfakes. This entails severe threats including public opinion manipulation, geopolitical tensions, chaos in financial markets, scams, defamation and identity theft among others. Therefore, it is imperative to develop techniques to prevent, detect, and stop the spreading of deepfake content. Along these lines, the goal of this paper is to present a big picture perspective of the deepfake paradigm, by reviewing current and future trends. First, a compact summary of DL techniques used for deepfakes is presented. Then, a review of the fight between generation and detection techniques is elaborated. Moreover, we delve into the potential that new technologies, such as distributed ledgers and blockchain, can offer with regard to cybersecurity and the fight against digital deception. Two scenarios of application, including online social networks engineering attacks and Internet of Things, are reviewed where main insights and open challenges are tackled. Finally, future trends and research lines are discussed, pointing out potential key agents and technologies.},
  langid = {english},
  keywords = {Artificial intelligence,Artificial Intelligence,Blockchain,Deep learning,Deepfake,Digital deception,GAN}
}

@online{goodfellowGenerativeAdversarialNetworks2014,
  title = {Generative {{Adversarial Networks}}},
  author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  date = {2014-06-10},
  eprint = {1406.2661},
  eprinttype = {arXiv},
  eprintclass = {stat},
  doi = {10.48550/arXiv.1406.2661},
  url = {http://arxiv.org/abs/1406.2661},
  urldate = {2025-06-02},
  abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning}
}

@article{grohHumanDetectionPolitical2024,
  title = {Human Detection of Political Speech Deepfakes across Transcripts, Audio, and Video},
  author = {Groh, Matthew and Sankaranarayanan, Aruna and Singh, Nikhil and Kim, Dong Young and Lippman, Andrew and Picard, Rosalind},
  date = {2024-09-02},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {15},
  number = {1},
  pages = {7629},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-024-51998-z},
  url = {https://www.nature.com/articles/s41467-024-51998-z},
  urldate = {2025-07-11},
  abstract = {Recent advances in technology for hyper-realistic visual and audio effects provoke the concern that deepfake videos of political speeches will soon be indistinguishable from authentic video. We conduct 5 pre-registered randomized experiments with N = 2215 participants to evaluate how accurately humans distinguish real political speeches from fabrications across base rates of misinformation, audio sources, question framings with and without priming, and media modalities. We do not find base rates of misinformation have statistically significant effects on discernment. We find deepfakes with audio produced by the state-of-the-art text-to-speech algorithms are harder to discern than the same deepfakes with voice actor audio. Moreover across all experiments and question framings, we find audio and visual information enables more accurate discernment than text alone: human discernment relies more on how something is said, the audio-visual cues, than what is said, the speech content.},
  langid = {english},
  keywords = {Communication,Decision making,Human behaviour,Technology}
}

@online{guptaPhotorealisticVideoGeneration,
  title = {Photorealistic {{Video Generation}} with {{Diffusion Models}}},
  author = {Gupta, Agrim and Yu, Lijun and Sohn, Kihyuk and Gu, Xiuye and {Meera Hahn} and {Li Fei-Fei} and {Irfan Essa} and {Lu Jiang} and {José Lezama}},
  url = {https://arxiv.org/html/2312.06662v1},
  urldate = {2025-06-13}
}

@article{harrisVideoDemandWhat2021,
  title = {Video on Demand: What Deepfakes Do and How They Harm},
  shorttitle = {Video on Demand},
  author = {Harris, Keith Raymond},
  date = {2021-12-01},
  journaltitle = {Synthese},
  shortjournal = {Synthese},
  volume = {199},
  number = {5},
  pages = {13373--13391},
  issn = {1573-0964},
  doi = {10.1007/s11229-021-03379-y},
  url = {https://doi.org/10.1007/s11229-021-03379-y},
  urldate = {2025-04-30},
  abstract = {This paper defends two main theses related to emerging deepfake technology. First, fears that deepfakes will bring about epistemic catastrophe are overblown. Such concerns underappreciate that the evidential power of video derives not solely from its content, but also from its source. An audience may find even the most realistic video evidence unconvincing when it is delivered by a dubious source. At the same time, an audience may find even weak video evidence compelling so long as it is delivered by a trusted source. The growing prominence of deepfake content is unlikely to change this fundamental dynamic. Thus, through appropriate patterns of trust, whatever epistemic threat deepfakes pose can be substantially mitigated. The second main thesis is that focusing on deepfakes that are intended to deceive, as epistemological discussions of the technology tend to do, threatens to overlook a further effect of this technology. Even where deepfake content is not regarded by its audience as veridical, it may cause its viewers to develop psychological associations based on that content. These associations, even without rising to the level of belief, may be harmful to the individuals depicted and more generally. Moreover, these associations may develop in cases in which the video content is realistic, but the audience is dubious of the content in virtue of skepticism toward its source. Thus, even if—as I suggest—epistemological concerns about deepfakes are overblown, deepfakes may nonetheless be psychologically impactful and may do great harm.},
  langid = {english},
  keywords = {Deception,Deepfakes,Pornography,Social epistemology,Testimony,Trust}
}

@article{hasanCombatingDeepfakeVideos2019,
  title = {Combating {{Deepfake Videos Using Blockchain}} and {{Smart Contracts}}},
  author = {Hasan, Haya R. and Salah, Khaled},
  date = {2019},
  journaltitle = {IEEE Access},
  volume = {7},
  pages = {41596--41606},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2019.2905689},
  url = {https://ieeexplore.ieee.org/document/8668407},
  urldate = {2025-05-29},
  abstract = {With the rise of artificial intelligence (AI) and deep learning techniques, fake digital contents have proliferated in recent years. Fake footage, images, audios, and videos (known as deepfakes) can be a scary and dangerous phenomenon and can have the potential of altering the truth and eroding trust by giving false reality. Proof of authenticity (PoA) of digital media is critical to help eradicate the epidemic of forged content. Current solutions lack the ability to provide history tracking and provenance of digital media. In this paper, we provide a solution and a general framework using Ethereum smart contracts to trace and track the provenance and history of digital content to its original source even if the digital content is copied multiple times. The smart contract utilizes the hashes of the interplanetary file system (IPFS) used to store digital content and its metadata. Our solution focuses on video content, but the solution framework provided in this paper is generic enough and can be applied to any other form of digital content. Our solution relies on the principle that if the content can be credibly traced to a trusted or reputable source, the content can then be real and authentic. The full code of the smart contract has been made publicly available at Github.},
  keywords = {AI,Artificial intelligence,blockchain,Blockchain,deepfake,Ethereum,History,Metadata,smart contracts,Smart contracts}
}

@article{hinrichsInteractivePublicDisplays2013,
  title = {Interactive {{Public Displays}}},
  author = {Hinrichs, Uta and Carpendale, Sheelagh and Valkanova, Nina and Kuikkaniemi, Kai and Jacucci, Giulio and Vande Moere, Andrew},
  date = {2013-03},
  journaltitle = {IEEE Computer Graphics and Applications},
  volume = {33},
  number = {2},
  pages = {25--27},
  issn = {1558-1756},
  doi = {10.1109/MCG.2013.28},
  url = {https://ieeexplore.ieee.org/abstract/document/6482534},
  urldate = {2025-04-29},
  abstract = {Public-display installations can range from large-scale media facades that are embedded in architectural structures and that people can interact with only from a distance, to direct-touch interactive kiosks that provide information of local interest. These different scenarios impose different challenges and research questions regarding the design of interfaces and interaction techniques. The articles in this special issue present snapshots of several ways that researchers are addressing these challenges.},
  keywords = {computer graphics,Data visualization,Displays,gestural interaction,interactive displays,Interactive systems,Media,motion tracking,public displays,public spaces,Special issues and sections,Urban areas}
}

@online{hoDenoisingDiffusionProbabilistic2020,
  title = {Denoising {{Diffusion Probabilistic Models}}},
  author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  date = {2020-12-16},
  eprint = {2006.11239},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2006.11239},
  url = {http://arxiv.org/abs/2006.11239},
  urldate = {2025-06-13},
  abstract = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN. Our implementation is available at https://github.com/hojonathanho/diffusion},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning}
}

@software{IsarHive2025,
  title = {Isar/Hive},
  date = {2025-07-20T08:00:14Z},
  origdate = {2019-07-08T22:47:01Z},
  url = {https://github.com/isar/hive},
  urldate = {2025-07-20},
  abstract = {Lightweight and blazing fast key-value database written in pure Dart.},
  organization = {Isar Database},
  keywords = {dart,database,encryption,flutter,hive,key-value,nosql}
}

@online{juefei-xuCounteringMaliciousDeepFakes2022,
  title = {Countering {{Malicious DeepFakes}}: {{Survey}}, {{Battleground}}, and {{Horizon}}},
  shorttitle = {Countering {{Malicious DeepFakes}}},
  author = {Juefei-Xu, Felix and Wang, Run and Huang, Yihao and Guo, Qing and Ma, Lei and Liu, Yang},
  date = {2022-03-23},
  eprint = {2103.00218},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2103.00218},
  url = {http://arxiv.org/abs/2103.00218},
  urldate = {2025-05-02},
  abstract = {The creation or manipulation of facial appearance through deep generative approaches, known as DeepFake, have achieved significant progress and promoted a wide range of benign and malicious applications, e.g., visual effect assistance in movie and misinformation generation by faking famous persons. The evil side of this new technique poses another popular study, i.e., DeepFake detection aiming to identify the fake faces from the real ones. With the rapid development of the DeepFake-related studies in the community, both sides have formed the relationship of battleground, pushing the improvements of each other and inspiring new directions, e.g., the evasion of DeepFake detection. Nevertheless, the overview of such battleground and the new direction is unclear and neglected by recent surveys due to the rapid increase of related publications, limiting the in-depth understanding of the tendency and future works. To fill this gap, in this paper, we provide a comprehensive overview and detailed analysis of the research work on the topic of DeepFake generation, DeepFake detection as well as evasion of DeepFake detection, with more than 318 research papers carefully surveyed. We present the taxonomy of various DeepFake generation methods and the categorization of various DeepFake detection methods, and more importantly, we showcase the battleground between the two parties with detailed interactions between the adversaries (DeepFake generation) and the defenders (DeepFake detection). The battleground allows fresh perspective into the latest landscape of the DeepFake research and can provide valuable analysis towards the research challenges and opportunities as well as research trends and future directions. We also elaborately design interactive diagrams (http://www.xujuefei.com/dfsurvey) to allow researchers to explore their own interests on popular DeepFake generators or detectors.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{kernerPornDiscreditationEpistemic2021,
  title = {Beyond {{Porn}} and {{Discreditation}}: {{Epistemic Promises}} and {{Perils}} of {{Deepfake Technology}} in {{Digital Lifeworlds}}},
  shorttitle = {Beyond {{Porn}} and {{Discreditation}}},
  author = {Kerner, Catherine and Risse, Mathias},
  date = {2021-04-01},
  journaltitle = {Moral Philosophy and Politics},
  volume = {8},
  number = {1},
  pages = {81--108},
  publisher = {De Gruyter},
  issn = {2194-5624},
  doi = {10.1515/mopp-2020-0024},
  url = {https://www.degruyterbrill.com/document/doi/10.1515/mopp-2020-0024/html?lang=de},
  urldate = {2025-04-29},
  abstract = {Deepfakes are a new form of synthetic media that broke upon the world in 2017. Bringing photoshopping to video, deepfakes replace people in existing videos with someone else’s likeness. Currently most of their reach is limited to pornography, and they are also used to discredit people. However, deepfake technology has many epistemic promises and perils, which concern how we fare as knowers. Our goal is to help set an agenda around these matters, to make sure this technology can help realize epistemic rights and epistemic justice and unleash human creativity, rather than inflict epistemic wrongs of any sort. Our project is exploratory in nature, and we do not aim to offer conclusive answers at this early stage. There is a need to remain vigilant to make sure the downsides do not outweigh the upsides, and that will be a tall order.},
  langid = {english}
}

@inproceedings{khamisChallengesDesignSpace2016,
  title = {Challenges and Design Space of Gaze-Enabled Public Displays},
  booktitle = {Proceedings of the 2016 {{ACM International Joint Conference}} on {{Pervasive}} and {{Ubiquitous Computing}}: {{Adjunct}}},
  author = {Khamis, Mohamed and Alt, Florian and Bulling, Andreas},
  date = {2016-09-12},
  series = {{{UbiComp}} '16},
  pages = {1736--1745},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/2968219.2968342},
  url = {https://dl.acm.org/doi/10.1145/2968219.2968342},
  urldate = {2025-04-28},
  abstract = {Gaze is an attractive modality for public displays, hence the recent years saw an increase in deployments of gaze-enabled public displays. Although gaze has been thoroughly investigated for desktop scenarios, gaze-enabled public displays present new challenges that are unique to this setup. In contrast to desktop settings, public displays (1) cannot afford requiring eye tracker calibration, (2) expect users to interact from different positions, and (3) expect multiple users to interact simultaneously. In this work we discuss these challenges, and explore the design space of gaze-enabled public displays. We conclude by discussing how the current state of research stands wrt. the identified challenges, and highlight directions for future work.},
  isbn = {978-1-4503-4462-3}
}

@inproceedings{khamisEyeScoutActiveEye2017,
  title = {{{EyeScout}}: {{Active Eye Tracking}} for {{Position}} and {{Movement Independent Gaze Interaction}} with {{Large Public Displays}}},
  shorttitle = {{{EyeScout}}},
  booktitle = {Proceedings of the 30th {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  author = {Khamis, Mohamed and Hoesl, Axel and Klimczak, Alexander and Reiss, Martin and Alt, Florian and Bulling, Andreas},
  date = {2017-10-20},
  pages = {155--166},
  publisher = {ACM},
  location = {Québec City QC Canada},
  doi = {10.1145/3126594.3126630},
  url = {https://dl.acm.org/doi/10.1145/3126594.3126630},
  urldate = {2025-04-29},
  abstract = {While gaze holds a lot of promise for hands-free interaction with public displays, remote eye trackers with their confined tracking box restrict users to a single stationary position in front of the display. We present EyeScout, an active eye tracking system that combines an eye tracker mounted on a rail system with a computational method to automatically detect and align the tracker with the user’s lateral movement. EyeScout addresses key limitations of current gaze-enabled large public displays by offering two novel gaze-interaction modes for a single user: In “Walk then Interact” the user can walk up to an arbitrary position in front of the display and interact, while in “Walk and Interact” the user can interact even while on the move. We report on a user study that shows that EyeScout is well perceived by users, extends a public display’s sweet spot into a sweet line, and reduces gaze interaction kickoff time to 3.5 seconds – a 62\% improvement over state of the art solutions. We discuss sample applications that demonstrate how EyeScout can enable position and movement-independent gaze interaction with large public displays.},
  eventtitle = {{{UIST}} '17: {{The}} 30th {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  isbn = {978-1-4503-4981-9},
  langid = {english}
}

@online{kurtknutsson10CelebsMost2024,
  type = {Text.Article},
  title = {10 Celebs Most Targeted by Malicious Deepfake Scams, Dangerous Search Results},
  author = {Kurt Knutsson, CyberGuy Report},
  date = {2024-10-28},
  publisher = {Fox News},
  url = {https://www.foxnews.com/tech/10-celebs-most-targeted-malicious-deepfake-scams-dangerous-search-results},
  urldate = {2025-05-07},
  abstract = {Tech expert Kurt “CyberGuy" Knutsson provides a list of 10 celebrities who are the most targeted by deepfake scams, including Tom Hanks.},
  langid = {american},
  organization = {Fox News},
  annotation = {Last Modified: 2024-10-28T16:20:08-04:00}
}

@inproceedings{lyuDeepfakeDetectionCurrent2020,
  title = {Deepfake {{Detection}}: {{Current Challenges}} and {{Next Steps}}},
  shorttitle = {Deepfake {{Detection}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Multimedia}} \& {{Expo Workshops}} ({{ICMEW}})},
  author = {Lyu, Siwei},
  date = {2020-07},
  pages = {1--6},
  doi = {10.1109/ICMEW46912.2020.9105991},
  url = {https://ieeexplore.ieee.org/document/9105991},
  urldate = {2025-04-29},
  abstract = {High quality fake videos and audios generated by AI- algorithms (the deep fakes) have started to challenge the status of videos and audios as definitive evidence of events. In this paper, we highlight a few of these challenges and discuss the research opportunities in this direction.},
  eventtitle = {2020 {{IEEE International Conference}} on {{Multimedia}} \& {{Expo Workshops}} ({{ICMEW}})},
  keywords = {DeepFake videos,detection techniques,digital media forensics,Forensics,Hair,Media,Prediction algorithms,Skin,Social networking (online),Visualization}
}

@article{maderIdentifyingComputerGeneratedPortraits2017,
  title = {Identifying {{Computer-Generated Portraits}}: {{The Importance}} of {{Training}} and {{Incentives}}},
  shorttitle = {Identifying {{Computer-Generated Portraits}}},
  author = {Mader, Brandon and Banks, Martin S. and Farid, Hany},
  date = {2017-09-01},
  journaltitle = {Perception},
  shortjournal = {Perception},
  volume = {46},
  number = {9},
  pages = {1062--1076},
  publisher = {SAGE Publications Ltd STM},
  issn = {0301-0066},
  doi = {10.1177/0301006617713633},
  url = {https://doi.org/10.1177/0301006617713633},
  urldate = {2025-07-12},
  abstract = {The past two decades have seen remarkable advances in photo-realistic rendering of everything from inanimate objects to landscapes, animals, and humans. We previously showed that despite these tremendous advances, human observers remain fairly good at distinguishing computer-generated from photographic images. Building on these results, we describe a series of follow-up experiments that reveal how to improve observer performance. Of general interest to anyone performing psychophysical studies on Mechanical Turk or similar platforms, we find that observer performance can be significantly improved with the proper incentives.},
  langid = {english}
}

@online{mahmudDeepInsightsDeepfake2023,
  title = {Deep {{Insights}} of {{Deepfake Technology}} : {{A Review}}},
  shorttitle = {Deep {{Insights}} of {{Deepfake Technology}}},
  author = {Mahmud, Bahar Uddin and Sharmin, Afsana},
  date = {2023-01-08},
  eprint = {2105.00192},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2105.00192},
  url = {http://arxiv.org/abs/2105.00192},
  urldate = {2025-04-29},
  abstract = {Under the aegis of computer vision and deep learning technology, a new emerging techniques has introduced that anyone can make highly realistic but fake videos, images even can manipulates the voices. This technology is widely known as Deepfake Technology. Although it seems interesting techniques to make fake videos or image of something or some individuals but it could spread as misinformation via internet. Deepfake contents could be dangerous for individuals as well as for our communities, organizations, countries religions etc. As Deepfake content creation involve a high level expertise with combination of several algorithms of deep learning, it seems almost real and genuine and difficult to differentiate. In this paper, a wide range of articles have been examined to understand Deepfake technology more extensively. We have examined several articles to find some insights such as what is Deepfake, who are responsible for this, is there any benefits of Deepfake and what are the challenges of this technology. We have also examined several creation and detection techniques. Our study revealed that although Deepfake is a threat to our societies, proper measures and strict regulations could prevent this.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning}
}

@article{maqsoodDesignDevelopmentEvaluation2021,
  title = {Design, {{Development}}, and {{Evaluation}} of a {{Cybersecurity}}, {{Privacy}}, and {{Digital Literacy Game}} for {{Tweens}}},
  author = {Maqsood, Sana and Chiasson, Sonia},
  date = {2021-09-30},
  journaltitle = {ACM Trans. Priv. Secur.},
  volume = {24},
  number = {4},
  pages = {28:1--28:37},
  issn = {2471-2566},
  doi = {10.1145/3469821},
  url = {https://dl.acm.org/doi/10.1145/3469821},
  urldate = {2025-07-15},
  abstract = {Tweens are avid users of digital media, which exposes them to various online threats. Teachers are primarily expected to teach children safe online behaviours, despite not necessarily having the required training or classroom tools to support this education. Using the theory of procedural rhetoric and established game design principles, we designed a classroom-based cybersecurity, privacy, and digital literacy game for tweens that has since been deployed to over 300 Canadian elementary schools. The game, A Day in the Life of the JOs, teaches children about 25 cybersecurity, privacy, and digital literacy topics and allows them to practice what they have learned in a simulated environment. We employed a user-centered design process to create the game, iteratively testing its design and effectiveness with children and teachers through five user studies (with a total of 63 child participants and 21 teachers). Our summative evaluation with children showed that the game improved their cybersecurity, privacy, and digital literacy knowledge and behavioural intent and was positively received by them. Our summative evaluation with teachers also showed positive results. Teachers liked that the game represented the authentic experiences of children on digital media and that it aligned with their curriculum requirements; they were interested in using it in their classrooms. In this article, we discuss our process and experience of designing a production quality game for children and provide evidence of its effectiveness with both children and teachers.}
}

@article{meakerSlovakiasElectionDeepfakes,
  entrysubtype = {magazine},
  title = {Slovakia’s {{Election Deepfakes Show AI Is}} a {{Danger}} to {{Democracy}}},
  author = {Meaker, Morgan},
  journaltitle = {Wired},
  issn = {1059-1028},
  url = {https://www.wired.com/story/slovakias-election-deepfakes-show-ai-is-a-danger-to-democracy/},
  urldate = {2025-05-05},
  abstract = {Fact-checkers scrambled to deal with faked audio recordings released days before a tight election, in a warning for other countries with looming votes.},
  langid = {american},
  keywords = {content moderation,disinformation,elections,fake news,politics,russia,social media}
}

@inproceedings{memarovicUsingPublicDisplays2012,
  title = {Using Public Displays to Stimulate Passive Engagement, Active Engagement, and Discovery in Public Spaces},
  booktitle = {Proceedings of the {{Media Architecture Biennale Conference}}: {{Participation}}},
  author = {Memarovic, Nemanja and Langheinrich, Marc and Alt, Florian and Elhart, Ivan and Hosio, Simo and Rubegni, Elisa},
  date = {2012-11-15},
  pages = {55--64},
  publisher = {ACM},
  location = {Aarhus Denmark},
  doi = {10.1145/2421076.2421086},
  url = {https://dl.acm.org/doi/10.1145/2421076.2421086},
  urldate = {2025-04-29},
  abstract = {In their influential book “Public space” Carr et al. describe essential human needs that public spaces fulfill: (1) passive engagement with the environment, where we observe what others are doing; (2) active engagement through intellectual challenges posed by the space, or through engagement with the people in it; and (3) excitement of novel discoveries within the space. An often underused resource in public spaces – public displays – can be used to stimulate these needs. In this paper we argue for a new research direction that explores how public displays can stimulate such essential needs in public spaces. We describe and conceptualize related processes that occur around public displays, based on indepth observations of people interacting with a publicly fielded display application in a city center. Our conceptualization is meant to lay the foundations for designing engaging public display systems that stimulate PACD, and for supporting the analysis of existing deployments.},
  eventtitle = {{{MAB}} '12: {{Media Architecture Biennale}}},
  isbn = {978-1-4503-1792-4},
  langid = {english}
}

@article{mirskyCreationDetectionDeepfakes2021,
  title = {The {{Creation}} and {{Detection}} of {{Deepfakes}}: {{A Survey}}},
  shorttitle = {The {{Creation}} and {{Detection}} of {{Deepfakes}}},
  author = {Mirsky, Yisroel and Lee, Wenke},
  date = {2021-01-02},
  journaltitle = {ACM Comput. Surv.},
  volume = {54},
  number = {1},
  pages = {7:1--7:41},
  issn = {0360-0300},
  doi = {10.1145/3425780},
  url = {https://dl.acm.org/doi/10.1145/3425780},
  urldate = {2025-06-01},
  abstract = {Generative deep learning algorithms have progressed to a point where it is difficult to tell the difference between what is real and what is fake. In 2018, it was discovered how easy it is to use this technology for unethical and malicious applications, such as the spread of misinformation, impersonation of political leaders, and the defamation of innocent individuals. Since then, these “deepfakes” have advanced significantly.In this article, we explore the creation and detection of deepfakes and provide an in-depth view as to how these architectures work. The purpose of this survey is to provide the reader with a deeper understanding of (1) how deepfakes are created and detected, (2) the current trends and advancements in this domain, (3) the shortcomings of the current defense solutions, and (4) the areas that require further research and attention.}
}

@online{mitraWorldGenerativeAI2024,
  title = {The {{World}} of {{Generative AI}}: {{Deepfakes}} and {{Large Language Models}}},
  shorttitle = {The {{World}} of {{Generative AI}}},
  author = {Mitra, Alakananda and Mohanty, Saraju P. and Kougianos, Elias},
  date = {2024-02-06},
  eprint = {2402.04373},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.04373},
  url = {http://arxiv.org/abs/2402.04373},
  urldate = {2025-05-29},
  abstract = {We live in the era of Generative Artificial Intelligence (GenAI). Deepfakes and Large Language Models (LLMs) are two examples of GenAI. Deepfakes, in particular, pose an alarming threat to society as they are capable of spreading misinformation and changing the truth. LLMs are powerful language models that generate general-purpose language. However due to its generative aspect, it can also be a risk for people if used with ill intentions. The ethical use of these technologies is a big concern. This short article tries to find out the interrelationship between them.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Computers and Society}
}

@online{mogaviSoraOpenAIsPrelude2024,
  title = {Sora {{OpenAI}}'s {{Prelude}}: {{Social Media Perspectives}} on {{Sora OpenAI}} and the {{Future}} of {{AI Video Generation}}},
  shorttitle = {Sora {{OpenAI}}'s {{Prelude}}},
  author = {Mogavi, Reza Hadi and Wang, Derrick and Tu, Joseph and Hadan, Hilda and Sgandurra, Sabrina A. and Hui, Pan and Nacke, Lennart E.},
  date = {2024-03-02},
  eprint = {2403.14665},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.14665},
  url = {http://arxiv.org/abs/2403.14665},
  urldate = {2025-05-29},
  abstract = {The rapid advancement of Generative AI (Gen-AI) is transforming Human-Computer Interaction (HCI), with significant implications across various sectors. This study investigates the public's perception of Sora OpenAI, a pioneering Gen-AI video generation tool, via social media discussions on Reddit before its release. It centers on two main questions: the envisioned applications and the concerns related to Sora's integration. The analysis forecasts positive shifts in content creation, predicting that Sora will democratize video marketing and innovate game development by making video production more accessible and economical. Conversely, there are concerns about deepfakes and the potential for disinformation, underscoring the need for strategies to address disinformation and bias. This paper contributes to the Gen-AI discourse by fostering discussion on current and future capabilities, enriching the understanding of public expectations, and establishing a temporal benchmark for user anticipation. This research underscores the necessity for informed, ethical approaches to AI development and integration, ensuring that technological advancements align with societal values and user needs.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computers and Society,Computer Science - Human-Computer Interaction}
}

@inproceedings{mullerRequirementsDesignSpace2010,
  title = {Requirements and Design Space for Interactive Public Displays},
  booktitle = {Proceedings of the 18th {{ACM}} International Conference on {{Multimedia}}},
  author = {Müller, Jörg and Alt, Florian and Michelis, Daniel and Schmidt, Albrecht},
  date = {2010-10-25},
  pages = {1285--1294},
  publisher = {ACM},
  location = {Firenze Italy},
  doi = {10.1145/1873951.1874203},
  url = {https://dl.acm.org/doi/10.1145/1873951.1874203},
  urldate = {2025-04-29},
  abstract = {Digital immersion is moving into public space. Interactive screens and public displays are deployed in urban environments, malls, and shop windows. Inner city areas, airports, train stations and stadiums are experiencing a transformation from traditional to digital displays enabling new forms of multimedia presentation and new user experiences. Imagine a walkway with digital displays that allows a user to immerse herself in her favorite content while moving through public space. In this paper we discuss the fundamentals for creating exciting public displays and multimedia experiences enabling new forms of engagement with digital content. Interaction in public space and with public displays can be categorized in phases, each having specific requirements. Attracting, engaging and motivating the user are central design issues that are addressed in this paper. We provide a comprehensive analysis of the design space explaining mental models and interaction modalities and we conclude a taxonomy for interactive public display from this analysis. Our analysis and the taxonomy are grounded in a large number of research projects, art installations and experience. With our contribution we aim at providing a comprehensive guide for designers and developers of interactive multimedia on public displays.},
  eventtitle = {{{MM}} '10: {{ACM Multimedia Conference}}},
  isbn = {978-1-60558-933-6},
  langid = {english}
}

@book{murphyMachineLearningProbabilistic2012,
  title = {Machine {{Learning}}: {{A Probabilistic Perspective}}},
  shorttitle = {Machine {{Learning}}},
  author = {Murphy, Kevin P.},
  date = {2012-09-07},
  eprint = {RC43AgAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {MIT Press},
  abstract = {A comprehensive introduction to machine learning that uses probabilistic models and inference as a unifying approach.Today's Web-enabled deluge of electronic data calls for automated methods of data analysis. Machine learning provides these, developing methods that can automatically detect patterns in data and then use the uncovered patterns to predict future data. This textbook offers a comprehensive and self-contained introduction to the field of machine learning, based on a unified, probabilistic approach.The coverage combines breadth and depth, offering necessary background material on such topics as probability, optimization, and linear algebra as well as discussion of recent developments in the field, including conditional random fields, L1 regularization, and deep learning. The book is written in an informal, accessible style, complete with pseudo-code for the most important algorithms. All topics are copiously illustrated with color images and worked examples drawn from such application domains as biology, text processing, computer vision, and robotics. Rather than providing a cookbook of different heuristic methods, the book stresses a principled model-based approach, often using the language of graphical models to specify models in a concise and intuitive way. Almost all the models described have been implemented in a MATLAB software package—PMTK (probabilistic modeling toolkit)—that is freely available online. The book is suitable for upper-level undergraduates with an introductory-level college math background and beginning graduate students.},
  isbn = {978-0-262-30432-0},
  langid = {english},
  pagetotal = {1102},
  keywords = {Computers / Artificial Intelligence / Computer Vision & Pattern Recognition,Computers / Data Science / Machine Learning,Mathematics / Algebra / Linear}
}

@inproceedings{murtezajPublicSecurityUser2025,
  title = {Public {{Security User Interfaces}}: {{Supporting Spontaneous Engagement}} with {{IT Security}}},
  shorttitle = {Public {{Security User Interfaces}}},
  booktitle = {Proceedings of the {{New Security Paradigms Workshop}}},
  author = {Murtezaj, Doruntina and Paneva, Viktorija and Distler, Verena and Alt, Florian},
  date = {2025-01-16},
  series = {{{NSPW}} '24},
  pages = {56--70},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3703465.3703470},
  url = {https://dl.acm.org/doi/10.1145/3703465.3703470},
  urldate = {2025-05-13},
  abstract = {We introduce the concept of Public Security User Interfaces as an innovative approach to enhancing cybersecurity awareness and promoting security behavior change among users in public spaces. We envision these interfaces as dynamic platforms that leverage interactive elements and contextual cues to deliver timely security information and guidance to users. We identify four key objectives: raising awareness, triggering actions, providing control, and sparking conversation. Drawing upon Sasse et al.’s Security Learning Curve, we outline the stages for supporting users in adopting new security-related routines into habits, encompassing knowledge, concordance, self-efficacy, implementation, embedding, and secure behavior. Insights from research on public displays and spontaneous interactions inform the design of public security user interfaces tailored to different environments and user groups. Furthermore, we propose research questions pertaining to stakeholders, content, user interface design, and effects on users and discuss challenges as well as limitations. Introducing public security user interfaces to bridge the gap between cybersecurity experts and lay users sets the stage for future research and development in this emerging field.},
  isbn = {979-8-4007-1128-2}
}

@article{nightingaleAIsynthesizedFacesAre2022,
  title = {{{AI-synthesized}} Faces Are Indistinguishable from Real Faces and More Trustworthy},
  author = {Nightingale, Sophie J. and Farid, Hany},
  date = {2022-02-22},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {119},
  number = {8},
  pages = {e2120481119},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2120481119},
  url = {https://www.pnas.org/doi/full/10.1073/pnas.2120481119},
  urldate = {2025-07-12},
  abstract = {Artificial intelligence (AI)–synthesized text, audio, image, and video are being weaponized for the purposes of nonconsensual intimate imagery, financial fraud, and disinformation campaigns. Our evaluation of the photorealism of AI-synthesized faces indicates that synthesis engines have passed through the uncanny valley and are capable of creating faces that are indistinguishable—and more trustworthy—than real faces.}
}

@article{nightingaleCanPeopleIdentify2017,
  title = {Can People Identify Original and Manipulated Photos of Real-World Scenes?},
  author = {Nightingale, Sophie J. and Wade, Kimberley A. and Watson, Derrick G.},
  date = {2017-07-18},
  journaltitle = {Cognitive Research: Principles and Implications},
  shortjournal = {Cognitive Research: Principles and Implications},
  volume = {2},
  number = {1},
  pages = {30},
  issn = {2365-7464},
  doi = {10.1186/s41235-017-0067-2},
  url = {https://doi.org/10.1186/s41235-017-0067-2},
  urldate = {2025-07-12},
  abstract = {Advances in digital technology mean that the creation of visually compelling photographic fakes is growing at an incredible speed. The prevalence of manipulated photos in our everyday lives invites an important, yet largely unanswered, question: Can people detect photo forgeries? Previous research using simple computer-generated stimuli suggests people are poor at detecting geometrical inconsistencies within a scene. We do not know, however, whether such limitations also apply to real-world scenes that contain common properties that the human visual system is attuned to processing. In two experiments we asked people to detect and locate manipulations within images of real-world scenes. Subjects demonstrated a limited ability to detect original and manipulated images. Furthermore, across both experiments, even when subjects correctly detected manipulated images, they were often unable to locate the manipulation. People’s ability to detect manipulated images was positively correlated with the extent of disruption to the underlying structure of the pixels in the photo. We also explored whether manipulation type and individual differences were associated with people’s ability to identify manipulations. Taken together, our findings show, for the first time, that people have poor ability to identify whether a real-world image is original or has been manipulated. The results have implications for professionals working with digital images in legal, media, and other domains.},
  keywords = {Digital image forensics,Photo manipulation,Psychology and law,Real-world scenes,Visual processing}
}

@online{PapersCodeMachine,
  title = {Papers with {{Code}} - {{Machine Learning Datasets}}},
  url = {https://paperswithcode.com/datasets?task=deepfake-detection&mod=videos},
  urldate = {2025-07-16},
  abstract = {15 datasets • 168989 papers with code.},
  langid = {english}
}

@article{parkerDoesPublicStill2018,
  title = {Does the {{Public Still Look}} at {{Public Displays}}? {{A Field Observation}} of {{Public Displays}} in the {{Wild}}},
  shorttitle = {Does the {{Public Still Look}} at {{Public Displays}}?},
  author = {Parker, Callum and Tomitsch, Martin and Kay, Judy},
  date = {2018-07-05},
  journaltitle = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
  volume = {2},
  number = {2},
  pages = {73:1--73:24},
  doi = {10.1145/3214276},
  url = {https://dl.acm.org/doi/10.1145/3214276},
  urldate = {2025-05-15},
  abstract = {Public displays are widely used for displaying information in public space, such as shopping centres. They are typically programmed to display advertisements or general information about the space in which they are situated. Due to recent advances in technology, public displays are becoming ubiquitous in space around cities and can potentially enable new interactions with public space. However, despite these advances, research reports that public displays are often found to be: (1) generally irrelevant to the space in which they are situated; and (2) ignored by passers-by. Although much research has focused on tackling these issues, a gap remains regarding knowledge about how public displays in the wild are currently being used at a time when people are increasingly relying on their smartphones as a main source for accessing information and for connecting with others. The study reported in this article aims to address this gap by presenting new insights about the current practices of non-research public displays and their role in a hyperconnected society. To achieve this, we provide results from a field observation study of non-research public displays and contextualise our findings within an analysis of related work. This article makes three main contributions: (1) identifying how user engagement with public displays has changed over the past 10 years; (2) understanding how the pervasiveness of smartphones and other connected devices has modified whether users notice public displays and their interactions with public displays; and (3) outlining design recommendations and opportunities towards making public displays more relevant in a hyperconnected society.}
}

@online{pawelecPolitischeManipulationUnd2024,
  title = {Politische Manipulation und Desinformation},
  author = {Pawelec, Maria},
  date = {2024-12-05},
  url = {https://www.bpb.de/lernen/bewegtbild-und-politische-bildung/556305/politische-manipulation-und-desinformation/},
  urldate = {2025-05-05},
  abstract = {Mit der zunehmenden Verbreitung von Deepfakes steigt auch die Gefahr von politischer Einflussnahme durch die künstlich kreierten Videos.},
  langid = {ngerman},
  organization = {bpb.de}
}

@article{PDFAdvertisingPublic,
  title = {({{PDF}}) {{Advertising}} on {{Public Display Networks}}},
  journaltitle = {ResearchGate},
  doi = {10.1109/MC.2012.150},
  url = {https://www.researchgate.net/publication/255568655_Advertising_on_Public_Display_Networks},
  urldate = {2025-04-29},
  abstract = {PDF | For advertising-based public display networks to become truly pervasive, they must provide a tangible social benefit and be engaging without being... | Find, read and cite all the research you need on ResearchGate},
  langid = {english}
}

@inproceedings{PDFEnticingPeoplea,
  title = {({{PDF}}) {{Enticing People}} to {{Interact}} with {{Large Public Displays}} in {{Public Spaces}}.},
  booktitle = {{{ResearchGate}}},
  url = {https://www.researchgate.net/publication/221054596_Enticing_People_to_Interact_with_Large_Public_Displays_in_Public_Spaces},
  urldate = {2025-05-15},
  abstract = {PDF | Large displays are increasingly being placed in public places to support community and social activities. However, a major problem that has been... | Find, read and cite all the research you need on ResearchGate},
  langid = {english}
}

@article{PDFImpactDeepfake2025,
  title = {({{PDF}}) {{Impact}} of {{Deepfake Technology}} on {{Social Media}}: {{Detection}}, {{Misinformation}} and {{Societal Implications}}},
  shorttitle = {({{PDF}}) {{Impact}} of {{Deepfake Technology}} on {{Social Media}}},
  date = {2025-04-18},
  journaltitle = {ResearchGate},
  doi = {10.55549/epstem.1371792},
  url = {https://www.researchgate.net/publication/374761496_Impact_of_Deepfake_Technology_on_Social_Media_Detection_Misinformation_and_Societal_Implications},
  urldate = {2025-04-29},
  abstract = {PDF | Deepfake technology, which allows the manipulation and fabrication of audio, video, and images, has gained significant attention due to its... | Find, read and cite all the research you need on ResearchGate},
  langid = {english}
}

@article{PDFMultipurposeInteractive,
  title = {({{PDF}}) {{Multipurpose Interactive Public Displays}} in the {{Wild}}: {{Three Years Later}}},
  shorttitle = {({{PDF}}) {{Multipurpose Interactive Public Displays}} in the {{Wild}}},
  journaltitle = {ResearchGate},
  doi = {10.1109/MC.2012.115},
  url = {https://www.researchgate.net/publication/254059154_Multipurpose_Interactive_Public_Displays_in_the_Wild_Three_Years_Later},
  urldate = {2025-05-15},
  abstract = {PDF | Extended research on interactive public displays deployed in a city center reveals differences between the public's stated information needs and... | Find, read and cite all the research you need on ResearchGate},
  langid = {english}
}

@inproceedings{PDFNovelMachine,
  title = {({{PDF}}) {{A Novel Machine Learning}} Based {{Method}} for {{Deepfake Video Detection}} in {{Social Media}}},
  booktitle = {{{ResearchGate}}},
  doi = {10.1109/iSES50453.2020.00031},
  url = {https://www.researchgate.net/publication/351537649_A_Novel_Machine_Learning_based_Method_for_Deepfake_Video_Detection_in_Social_Media},
  urldate = {2025-05-29},
  abstract = {PDF | On Dec 1, 2020, Alakananda Mitra and others published A Novel Machine Learning based Method for Deepfake Video Detection in Social Media | Find, read and cite all the research you need on ResearchGate},
  langid = {english}
}

@article{PDFWayDeep2024,
  title = {({{PDF}}) {{On}} the Way to Deep Fake Democracy? {{Deep}} Fakes in Election Campaigns in 2023},
  shorttitle = {({{PDF}}) {{On}} the Way to Deep Fake Democracy?},
  date = {2024-12-09},
  journaltitle = {ResearchGate},
  doi = {10.1057/s41304-024-00482-9},
  url = {https://www.researchgate.net/publication/380126684_On_the_way_to_deep_fake_democracy_Deep_fakes_in_election_campaigns_in_2023},
  urldate = {2025-05-05},
  abstract = {PDF | The development of generative artificial intelligence raises justified concerns about the possibility of undermining trust in democratic... | Find, read and cite all the research you need on ResearchGate},
  langid = {english}
}

@online{ProjectOverviewDetect,
  title = {Project {{Overview}} ‹ {{Detect DeepFakes}}: {{How}} to Counteract Misinformation Created by {{AI}}},
  shorttitle = {Project {{Overview}} ‹ {{Detect DeepFakes}}},
  url = {https://www.media.mit.edu/projects/detect-fakes/overview/},
  urldate = {2025-07-11},
  abstract = {See for yourself how accurately you can identify AI-generated images at the\&nbsp;DetectFakes Experiment\&nbsp;and if you want to learn to spot deepfakes, please…},
  organization = {MIT Media Lab}
}

@online{proschofskyGooglesNeueVideoKI2025,
  title = {Googles neue Video-KI Veo3 sorgt für Hype im Internet – und Angst vor täuschend echten Fakes},
  author = {Proschofsky, Andreas},
  date = {2025-05-27},
  url = {https://www.derstandard.at/story/3000000271520/googles-neue-video-ki-veo3-sorgt-fuer-hype-im-internet-und-angst-vor-taeuschend-echten-fakes},
  urldate = {2025-05-29},
  abstract = {Die Kombination von Bild und Ton ergibt oft verblüffend echt wirkende Ergebnisse},
  langid = {naustrian},
  organization = {DER STANDARD}
}

@article{ranaDeepfakeDetectionSystematic2022,
  title = {Deepfake {{Detection}}: {{A Systematic Literature Review}}},
  shorttitle = {Deepfake {{Detection}}},
  author = {Rana, Md Shohel and Nobi, Mohammad Nur and Murali, Beddhu and Sung, Andrew H.},
  date = {2022},
  journaltitle = {IEEE Access},
  volume = {10},
  pages = {25494--25513},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2022.3154404},
  url = {https://ieeexplore.ieee.org/abstract/document/9721302},
  urldate = {2025-04-29},
  abstract = {Over the last few decades, rapid progress in AI, machine learning, and deep learning has resulted in new techniques and various tools for manipulating multimedia. Though the technology has been mostly used in legitimate applications such as for entertainment and education, etc., malicious users have also exploited them for unlawful or nefarious purposes. For example, high-quality and realistic fake videos, images, or audios have been created to spread misinformation and propaganda, foment political discord and hate, or even harass and blackmail people. The manipulated, high-quality and realistic videos have become known recently as Deepfake. Various approaches have since been described in the literature to deal with the problems raised by Deepfake. To provide an updated overview of the research works in Deepfake detection, we conduct a systematic literature review (SLR) in this paper, summarizing 112 relevant articles from 2018 to 2020 that presented a variety of methodologies. We analyze them by grouping them into four different categories: deep learning-based techniques, classical machine learning-based methods, statistical techniques, and blockchain-based techniques. We also evaluate the performance of the detection capability of the various methods with respect to different datasets and conclude that the deep learning-based methods outperform other methods in Deepfake detection.},
  keywords = {Computational modeling,Deep learning,Deepfake detection,digital media forensics,Faces,Information integrity,Measurement,systematic literature review,video or image manipulation,Videos,Web pages}
}

@article{riniDeepfakesDeepHarms2022,
  title = {Deepfakes, {{Deep Harms}}},
  author = {Rini, Regina and Cohen, Leah},
  date = {2022-07-26},
  journaltitle = {Journal of Ethics and Social Philosophy},
  shortjournal = {JESP},
  volume = {22},
  number = {2},
  issn = {1559-3061},
  doi = {10.26556/jesp.v22i2.1628},
  url = {https://www.jesp.org},
  urldate = {2025-07-15},
  abstract = {Deepfakes are algorithmically modified video and audio recordings that project one person’s appearance on to that of another, creating an apparent recording of an event that never took place. Many scholars and journalists have begun attending to the political risks of deepfake deception. Here we investigate other ways in which deepfakes have the potential to cause deeper harms than have been appreciated. First, we consider a form of objectification that occurs in deepfaked ‘frankenporn’ that digitally fuses the parts of different women to create pliable characters incapable of giving consent to their depiction. Next, we develop the idea of ‘illocutionary wronging’, in which an individual is forced to engage in speech acts they would prefer to avoid in order to deny or correct the misleading evidence of a publicized deepfake. Finally, we consider the risk that deepfakes may facilitate campaigns of ‘panoptic gaslighting’, where many systematically altered recordings of a single person's life undermine their memory, eroding their sense of self and ability to engage with others. Taken together, these harms illustrate the roles that social epistemology and technological vulnerabilities play in human ethical life.},
  langid = {english}
}

@incollection{sasseRebootingITSecurity2023,
  title = {Rebooting {{IT Security Awareness}} – {{How Organisations Can Encourage}} and {{Sustain Secure Behaviours}}},
  booktitle = {Computer {{Security}}. {{ESORICS}} 2022 {{International Workshops}}},
  author = {Sasse, M. Angela and Hielscher, Jonas and Friedauer, Jennifer and Buckmann, Annalina},
  editor = {Katsikas, Sokratis and Cuppens, Frédéric and Kalloniatis, Christos and Mylopoulos, John and Pallas, Frank and Pohle, Jörg and Sasse, M. Angela and Abie, Habtamu and Ranise, Silvio and Verderame, Luca and Cambiaso, Enrico and Maestre Vidal, Jorge and Sotelo Monge, Marco Antonio and Albanese, Massimiliano and Katt, Basel and Pirbhulal, Sandeep and Shukla, Ankur},
  date = {2023},
  volume = {13785},
  pages = {248--265},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-031-25460-4_14},
  url = {https://link.springer.com/10.1007/978-3-031-25460-4_14},
  urldate = {2025-04-29},
  abstract = {Most organisations are using online security awareness training and simulated phishing attacks to encourage their employees to behave securely. Buying off-the-shelf training packages and making it mandatory for all employees to complete them is easy, and satisfies most regulatory and audit requirements, but does not lead to secure behaviour becoming a routine. In this paper, we identify the additional steps employees must go through to develop secure routines, and the blockers that stop a new behaviour from becoming a routine. Our key message is: security awareness as we know it is only the first step; organisations who want employees have to do more to smooth the path: they have to ensure that secure behaviour is feasible, and support their staff through the stages of the Security Behaviour Curve – concordance, selfefficacy, and embedding – for secure behaviour to become a routine. We provide examples of those organisational activities, and specific recommendations to different organisational stakeholders.},
  isbn = {978-3-031-25459-8 978-3-031-25460-4},
  langid = {english}
}

@inproceedings{sasseRebootingITSecurity2023a,
  title = {Rebooting {{IT Security Awareness}} – {{How Organisations Can Encourage}} and~{{Sustain Secure Behaviours}}},
  booktitle = {Computer {{Security}}. {{ESORICS}} 2022 {{International Workshops}}},
  author = {Sasse, M. Angela and Hielscher, Jonas and Friedauer, Jennifer and Buckmann, Annalina},
  editor = {Katsikas, Sokratis and Cuppens, Frédéric and Kalloniatis, Christos and Mylopoulos, John and Pallas, Frank and Pohle, Jörg and Sasse, M. Angela and Abie, Habtamu and Ranise, Silvio and Verderame, Luca and Cambiaso, Enrico and Maestre Vidal, Jorge and Sotelo Monge, Marco Antonio and Albanese, Massimiliano and Katt, Basel and Pirbhulal, Sandeep and Shukla, Ankur},
  date = {2023},
  pages = {248--265},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-031-25460-4_14},
  abstract = {Most organisations are using online security awareness training and simulated phishing attacks to encourage their employees to behave securely. Buying off-the-shelf training packages and making it mandatory for all employees to complete them is easy, and satisfies most regulatory and audit requirements, but does not lead to secure behaviour becoming a routine. In this paper, we identify the additional steps employees must go through to develop secure routines, and the blockers that stop a new behaviour from becoming a routine. Our key message is: security awareness as we know it is only the first step; organisations who want employees have to do more to smooth the path: they have to ensure that secure behaviour is feasible, and support their staff through the stages of the Security Behaviour Curve – concordance, self-efficacy, and embedding – for secure behaviour to become a routine. We provide examples of those organisational activities, and specific recommendations to different organisational stakeholders.},
  isbn = {978-3-031-25460-4},
  langid = {english},
  keywords = {Human factors in IT security,IT-security for IT professionals,Organisational security,Security awareness,Security learning curve,Security training}
}

@article{seowComprehensiveOverviewDeepfake2022,
  title = {A Comprehensive Overview of {{Deepfake}}: {{Generation}}, Detection, Datasets, and Opportunities},
  shorttitle = {A Comprehensive Overview of {{Deepfake}}},
  author = {Seow, Jia Wen and Lim, Mei Kuan and Phan, Raphaël C. W. and Liu, Joseph K.},
  date = {2022-11-07},
  journaltitle = {Neurocomputing},
  shortjournal = {Neurocomputing},
  volume = {513},
  pages = {351--371},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2022.09.135},
  url = {https://www.sciencedirect.com/science/article/pii/S0925231222012334},
  urldate = {2025-06-01},
  abstract = {When used maliciously, deepfake can pose detrimental implications to political and social forces including reducing public trust in institutions, damaging the reputation of prominent individuals, and influencing public opinions. As there is currently no specific law to address deepfakes, thus deepfake detection, which is an action to discriminate pristine media from deepfake media, plays a vital role in identifying and thwarting deepfake. This paper provides readers with a comprehensive and easy-to-understand state-of-the-art related to deepfake generation and detection. Specifically, we provide a synthesized overview and recent progress in deepfakes by categorizing our review into deepfake generation and detection. We underline publicly available deepfake generation tools and datasets for benchmarking. We also provide research insights, discuss existing gaps, and present trends for future research to facilitate the development of deepfake research.},
  keywords = {Deepfake,Face manipulation,Forgery generation detection}
}

@online{settlesPolitiFactDemystifiesDeepfake,
  title = {{{PolitiFact}} Demystifies Deepfake Videos},
  author = {Settles, Gabrielle},
  url = {https://www.politifact.com/article/2023/apr/19/how-to-detect-deepfake-videos-like-a-fact-checker/},
  urldate = {2025-07-16},
  abstract = {With the growing popularity and constant improvement of artificial intelligence, it’s tough to decipher what’s real or f},
  langid = {american},
  organization = {@politifact}
}

@online{tewariMoFAModelbasedDeep2017,
  title = {{{MoFA}}: {{Model-based Deep Convolutional Face Autoencoder}} for {{Unsupervised Monocular Reconstruction}}},
  shorttitle = {{{MoFA}}},
  author = {Tewari, Ayush and Zollhöfer, Michael and Kim, Hyeongwoo and Garrido, Pablo and Bernard, Florian and Pérez, Patrick and Theobalt, Christian},
  date = {2017-12-07},
  eprint = {1703.10580},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1703.10580},
  url = {http://arxiv.org/abs/1703.10580},
  urldate = {2025-05-29},
  abstract = {In this work we propose a novel model-based deep convolutional autoencoder that addresses the highly challenging problem of reconstructing a 3D human face from a single in-the-wild color image. To this end, we combine a convolutional encoder network with an expert-designed generative model that serves as decoder. The core innovation is our new differentiable parametric decoder that encapsulates image formation analytically based on a generative model. Our decoder takes as input a code vector with exactly defined semantic meaning that encodes detailed face pose, shape, expression, skin reflectance and scene illumination. Due to this new way of combining CNN-based with model-based face reconstruction, the CNN-based encoder learns to extract semantically meaningful parameters from a single monocular input image. For the first time, a CNN encoder and an expert-designed generative model can be trained end-to-end in an unsupervised manner, which renders training on very large (unlabeled) real world data feasible. The obtained reconstructions compare favorably to current state-of-the-art approaches in terms of quality and richness of representation.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@online{TurkishPresidentialCandidate2023,
  title = {Turkish Presidential Candidate Quits Race after Release of Alleged Sex Tape},
  date = {2023-05-11T14:08:00},
  url = {https://www.theguardian.com/world/2023/may/11/muharrem-ince-turkish-presidential-candidate-withdraws-alleged-sex-tape},
  urldate = {2025-05-05},
  abstract = {Muharrem İnce pulls out just days from close election race saying alleged sex tape is deepfake},
  langid = {english},
  organization = {the Guardian}
}

@inproceedings{veenstraShouldPublicDisplays2015,
  title = {Should {{Public Displays}} Be {{Interactive}}? {{Evaluating}} the {{Impact}} of {{Interactivity}} on {{Audience Engagement}}},
  shorttitle = {Should {{Public Displays}} Be {{Interactive}}?},
  booktitle = {Proceedings of the 4th {{International Symposium}} on {{Pervasive Displays}}},
  author = {Veenstra, Mettina and Wouters, Niels and Kanis, Marije and Brandenburg, Stephan and family=Raa, given=Kevin, prefix=te, useprefix=true and Wigger, Bart and Vande Moere, Andrew},
  date = {2015-06-10},
  series = {{{PerDis}} '15},
  pages = {15--21},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/2757710.2757727},
  url = {https://dl.acm.org/doi/10.1145/2757710.2757727},
  urldate = {2025-07-14},
  abstract = {This paper describes a comparative case study that aims to uncover the quantifiable differences between non-interactive and interactive public displays in the urban environment. The study involved a large temporary interactive public display on a central city square showing a selection of custom-made content. We have evaluated the effect on passers-by and spectators in two conditions: 1) non-interactive (2102 passers-by, 228 viewers), by showing a content loop, and 2) interactive (1676 passers-by, 257 viewers), by adding physical pushbuttons for content selection and gaming. We discuss the influence of non-interactive and interactive public displays on: 1) attracting attention, 2) engaging people, 3) improving social dynamics within and among groups of viewers, and 4) catering for the suitable time of day. Based on our observations, we provide quantitative support for the hypothesis that interactive displays are more successful than non-interactive displays to engage viewers, and to make city centers more lively and attractive.},
  isbn = {978-1-4503-3608-6}
}

@online{Veo3Our,
  title = {Veo 3: {{Our}} State-of-the-Art Video Generation Model - {{YouTube}}},
  url = {https://www.youtube.com/playlist?list=PLqYmG7hTraZAwi0L13zfmM_r20Xps15xR},
  urldate = {2025-07-16}
}

@online{visionCyberSecurityAwareness,
  title = {Cyber {{Security Awareness Month}} - {{Digital Signage Template}} | {{Rise Vision}}},
  author = {Vision, Rise},
  url = {https://www.risevision.com/template-details/cyber-aware-month},
  urldate = {2025-07-16},
  abstract = {Cyber security is more important than ever. With our lives becoming more entangled in technology each year, it’s essential that we take the right steps to protect ourselves and our students! Use this striking template to observe National Cyber Security Awareness Month this October and educate your school on the seriousness of cyber security.},
  langid = {english}
}

@inproceedings{wangBecomingFeiEducational2025,
  title = {Becoming {{Fei}}: {{An Educational Game}} for~{{AI}} and~{{Data Science Education}} for~{{Novice Learners}}},
  shorttitle = {Becoming {{Fei}}},
  booktitle = {Learning and {{Collaboration Technologies}}},
  author = {Wang, Ning and Fu, Boxi and Dincer, Betul and Masur, Omkar and Faizi, David and Ravindran, Harshul and Wang, Julia and Lai, Devashish and Merchant, Chirag},
  editor = {Smith, Brian K. and Borge, Marcela},
  date = {2025},
  pages = {69--79},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-93746-0_6},
  abstract = {Artificial Intelligence (AI) is transforming our workforce. It is critical for the workforce and everyone in society to be literate in AI and data to excel in a world flowing with data and driven by AI. Until recently, there has been little knowledge and research into how to introduce AI to learners without an engineering background, such as the general public and pre-college students. One approach that has shown promise in AI and STEM disciplines is digital game-based learning. In this paper, we discuss the design of an educational game, Becoming Fei, that aims to introduce the basic concepts and processes of machine learning to learners without an engineering background.},
  isbn = {978-3-031-93746-0},
  langid = {english},
  keywords = {AI education,Data science education,Educational games,game-based learning}
}

@article{westerlundEmergenceDeepfakeTechnology2019,
  title = {The {{Emergence}} of {{Deepfake Technology}}: {{A Review}}},
  shorttitle = {The {{Emergence}} of {{Deepfake Technology}}},
  author = {Westerlund, Mika},
  date = {2019},
  journaltitle = {Technology Innovation Management Review},
  volume = {9},
  number = {11},
  pages = {40--53},
  publisher = {Talent First Network},
  location = {Ottawa},
  issn = {1927-0321},
  doi = {10.22215/timreview/1282}
}

@online{williampeeblesScalableDiffusionModels,
  title = {Scalable {{Diffusion Models}} with {{Transformers}}},
  author = {{William Peebles} and {Saining Xie}},
  url = {https://ar5iv.labs.arxiv.org/html/2212.09748},
  urldate = {2025-06-13},
  abstract = {We explore a new class of diffusion models based on the transformer architecture. We train latent diffusion models of images, replacing the commonly-used U-Net backbone with a transformer that operates on latent patche…},
  langid = {english},
  organization = {ar5iv}
}

@online{WomansDeepfakeBetrayal2025,
  title = {Woman's Deepfake Betrayal by Friend: '{{Every}} Moment Became Porn'},
  shorttitle = {Woman's Deepfake Betrayal by Friend},
  date = {2025-02-08},
  url = {https://www.bbc.com/news/articles/cm21j341m31o},
  urldate = {2025-05-05},
  abstract = {Australian teacher Hannah Grundy was left to track down the man posting deepfake pornography of her.},
  langid = {british}
}
